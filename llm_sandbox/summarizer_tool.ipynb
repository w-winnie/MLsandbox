{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19102427",
   "metadata": {},
   "source": [
    "Notebook containing tools to summarize AND interact with different content types (websites, pdfs, ppts, videos) <br>\n",
    "The Notebook employs various python packages to extract required contents from URLs <br>\n",
    "And employs an llm connector to connect to frontier llms (llama, mixtral, gemini, gpt etc - gpt-4o in this case) <br>\n",
    "There are different sections for eacvh content type and it contains summary and qna - which can be run in Test section under each <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40582dbb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04db731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e07a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm_connector import create_model_client, chat_with_model, get_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ca48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website Scraper\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa691a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF reader\n",
    "# !pip install PyPDF2\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "834b3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPT \n",
    "# !pip install python-pptx\n",
    "from pptx import Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f7d9b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube\n",
    "# !pip install youtube-transcript-api\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = get_model_response(\n",
    "    model_name=\"gpt-4o\",\n",
    "    user_message=\"What are the different types of clouds?\",\n",
    "    system_message=\"You are a helpful assistant with an expertise in meterology\"\n",
    ")\n",
    "\n",
    "if response:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a890db1",
   "metadata": {},
   "source": [
    "# Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40654a8",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b49bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "048383f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34152456",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "195e30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_website_summary = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b321f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_website_summary(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb2d2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_website(url):\n",
    "    website = Website(url)\n",
    "    response = get_model_response(\n",
    "        model_name=\"gpt-4o\",\n",
    "        user_message=get_user_prompt_website_summary(website),\n",
    "        system_message=system_prompt_website_summary\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188e07d",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6948b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_website_summary(url):\n",
    "    summary = summarize_website(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aca1c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o\n",
      "With system prompt: You are an assistant that analyzes the contents of...\n",
      "With user prompt: You are looking at a website titled Breaking News,...\n",
      "Using OpenAI with model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "CNN's website offers comprehensive coverage of current events, featuring news from categories such as US, World, Politics, Business, Health, Entertainment, Style, Travel, Sports, Science, and Climate. Key stories include geopolitical updates like the Ukraine-Russia and Israel-Hamas conflicts, domestic US politics involving former President Trump, and international business news highlighting mergers and market analyses. The site also discusses social issues, scientific discoveries, and cultural happenings. In addition, CNN provides analyses, opinion pieces, multimedia content, and a section known as CNN Underscored, which offers lifestyle tips and product recommendations. There are also interactive elements such as games, quizzes, and a variety of podcasts covering diverse topics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_website_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a451ac2",
   "metadata": {},
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df0d66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_website_qna = \"You are an assistant that analyzes the contents of a website \\\n",
    "and answers questions related to the content of the website, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a2d78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_website_qna(website, question):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows \\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    user_prompt += f\"\\n\\nPlease answer the following question related to this website: {question}\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f165e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def website_qna(url, question):\n",
    "    website = Website(url)\n",
    "    response = get_model_response(\n",
    "        model_name=\"gpt-4o\",\n",
    "        user_message=get_user_prompt_website_qna(website, question),\n",
    "        system_message=system_prompt_website_qna\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742c2f0",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97a6164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_website_answer(url, question):\n",
    "    answer = website_qna(url, question)\n",
    "    display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "382d210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o\n",
      "With system prompt: You are an assistant that analyzes the contents of...\n",
      "With user prompt: You are looking at a website titled Breaking News,...\n",
      "Using OpenAI with model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The website mentions that Tesla is involved in a settlement related to a lawsuit. Specifically, a lawsuit alleging pervasive workplace harassment faced by a Black worker at Tesla was settled. The article describes the settlement but does not provide additional details about its terms or implications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_website_answer(\"https://cnn.com\", \"What is happening with tesla?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358acc1a",
   "metadata": {},
   "source": [
    "# Research Paper\n",
    "passes the whole paper (better suited for smaller reserach papers/articles) <br>\n",
    "so for long papers refer to other solution in PDF_LLM repo with vector db and embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41a73b0",
   "metadata": {},
   "source": [
    "## Pdf Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a198be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        parsed_url = urlparse(url)\n",
    "        self.text = \"\"\n",
    "        self.title = \"No title found\"\n",
    "\n",
    "        if parsed_url.scheme in ('http', 'https'):\n",
    "            response = requests.get(self.url)\n",
    "            if response.status_code == 200:\n",
    "                pdf_bytes = BytesIO(response.content)\n",
    "                reader = PdfReader(pdf_bytes)\n",
    "                self._extract(reader)\n",
    "            else:\n",
    "                print(f\"Failed to fetch PDF. Status code: {response.status_code}\")\n",
    "        elif os.path.isfile(url):\n",
    "            try:\n",
    "                with open(url, 'rb') as pdf_file:\n",
    "                    reader = PdfReader(pdf_file)\n",
    "                    self._extract(reader)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading PDF: {e}\")\n",
    "        else:\n",
    "            print(f\"Invalid file path or URL: {url}\")\n",
    "\n",
    "    def _extract(self, reader):\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "        self.text = text\n",
    "        try:\n",
    "            self.title = reader.metadata.get(\"/Title\", \"No title found\") or \"No title found\"\n",
    "        except Exception:\n",
    "            self.title = \"No title found\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Paper(title='{self.title[:1000]}...')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper(title='Strategies for Improving the Resiliency of Distribution Networks in Electric Power Systems during Typhoon and Water-Logging Disasters...')\n"
     ]
    }
   ],
   "source": [
    "paper = Paper(\"d:/Projects/sandbox/data/energies.pdf\")\n",
    "print(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3783d3b5",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31437e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_paper_summary = \"You are a research assistant. Your job is to go through the provided article in details, understand the purpose, study the methods and techniques employed, arguments made and the conclusion.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35bcb857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_paper_summary(paper):\n",
    "    user_prompt = f\"You are looking at a paper titled {paper.title}\"\n",
    "    user_prompt += \"\\nPlease provide a short summary of this paper in markdown. \\\n",
    "    After the summary extract the following: \\\n",
    "    1) Title and Author of the research paper. \\\n",
    "    2) Year it was published it \\\n",
    "    3) Objective or aim of the research to specify why the research was conducted \\\n",
    "    4) Background or Introduction to explain the need to conduct this research or any topics the readers must have knowledge about \\\n",
    "    5) Type of research/study/experiment to explain what kind of research it is. \\\n",
    "    6) Methods or methodology to explain what the researchers did to conduct the research \\\n",
    "    7) Results and key findings to explain what the researchers found \\\n",
    "    8) Conclusion tells about the conclusions that can be drawn from this research including limitations and future direction \\\n",
    "    The contents of this paper is as follows:\\n\\n\"\n",
    "    user_prompt += paper.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f22c74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_paper(paper_url):\n",
    "    paper = Paper(paper_url)\n",
    "    response = get_model_response(\n",
    "        model_name=\"gpt-4o\",\n",
    "        user_message=get_user_prompt_paper_summary(paper),\n",
    "        system_message=system_prompt_paper_summary\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c6e5b",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b372daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_paper_summary(paper_url):\n",
    "    summary = summarize_paper(paper_url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac43fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o\n",
      "With system prompt: You are a research assistant. Your job is to go th...\n",
      "With user prompt: You are looking at a paper titled Strategies for I...\n",
      "Using OpenAI with model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Summary of the Paper\n",
       "\n",
       "The paper titled \"Strategies for Improving the Resiliency of Distribution Networks in Electric Power Systems during Typhoon and Water-Logging Disasters\" by Nan Ma et al., explores methods to enhance the resilience of urban electricity distribution networks that are susceptible to damage from typhoons and subsequent flooding. The research mainly focuses on predicting power-grid failure rates in such extreme conditions and suggests dynamic network reconstruction strategies to improve the resilience and flexibility of the grids. The proposed dynamic reconstruction method aims to effectively restore critical power supply post-disaster by optimizing network configuration in real-time, which shows significant improvement in maintaining power supply compared to traditional static methods.\n",
       "\n",
       "---\n",
       "\n",
       "1) **Title and Author of the Research Paper:**\n",
       "\n",
       "   **Title:** Strategies for Improving the Resiliency of Distribution Networks in Electric Power Systems during Typhoon and Water-Logging Disasters\n",
       "\n",
       "   **Authors:** Nan Ma, Ziwen Xu, Yijun Wang, Guowei Liu, Lisheng Xin, Dafu Liu, Ziyu Liu, Jiaju Shi, and Chen Chen.\n",
       "\n",
       "2) **Year it was Published:**\n",
       "\n",
       "   **Year:** 2024\n",
       "\n",
       "3) **Objective or Aim of the Research:**\n",
       "\n",
       "   The research aims to study the impact of typhoon and water-logging disasters on urban distribution networks and develop strategies to improve these networks' flexibility and resilience. It proposes a method for predicting failure rates of power grids during such events and suggests strategies for network elasticity improvement post-disaster.\n",
       "\n",
       "4) **Background or Introduction:**\n",
       "\n",
       "   Extreme weather events such as typhoons and log rains have become more frequent and pose severe challenges to urban public services such as power supply systems. This is due to potential infrastructure damage leading to power outages and economic losses. The need for improving resiliency and flexibility of power networks in response to these weather-induced challenges is imperative for sustainable urban development.\n",
       "\n",
       "5) **Type of Research/Study/Experiment:**\n",
       "\n",
       "   This research employs a methodological study, combining theories from hydrology, climate science, and electrical engineering to model and improve the resiliency of power distribution networks during natural disasters.\n",
       "\n",
       "6) **Methods or Methodology:**\n",
       "\n",
       "   The study utilized vulnerability curves to map wind speeds and water depths to predict failure probabilities of distribution network components during typhoons and floods. A multi-objective dynamic reconstruction model was built to adjust network configurations in real-time during disaster evolution. The model was tested on a modified 33-node and a 118-node distribution network with pre-loaded distributed generators.\n",
       "\n",
       "7) **Results and Key Findings:**\n",
       "\n",
       "   The findings demonstrated that the dynamic reconstruction strategy proposed effectively improved resiliency of the distribution network post-disaster compared to static reconstruction methods. In particular, it noted a 26% load supply improvement in the 33-node system and a near-total resiliency with close to 95% load supply in the 118-node system—significantly better performance over traditional methods.\n",
       "\n",
       "8) **Conclusion:**\n",
       "\n",
       "   The research concluded that the proposed dynamic reconstruction method enhances distribution network resilience under complex wind and flood conditions by maintaining power supply to critical loads more effectively than static strategies. It suggested that further work should refine fault predictions and incorporate integrated disaster response planning using weather information for more efficient resiliency strategies. This study emphasizes the importance of adaptive network configuration for sustainable urban energy supply management during natural disasters. Limitations identified include the assumptions in vulnerability modeling, urging future research for more tailored and precise resilience planning strategies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_paper_summary(\"d:/Projects/sandbox/data/energies.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca2324",
   "metadata": {},
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ebb31cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_paper_qna = \"You are a research assistant. Your job is to go through the provided article in details, understand the purpose, study the methods and techniques employed, arguments made and the conclusion.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "febfad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_paper_qna(website, question):\n",
    "    user_prompt = f\"You are looking at a paper titled {paper.title}. The contents of this paper is as follows:\\n\\n\"\n",
    "    user_prompt += paper.text\n",
    "    user_prompt += f\"\\n\\nPlease answer the following question related to this paper: {question}\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1509a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_qna(url, question):\n",
    "    paper = Paper(url)\n",
    "    response = get_model_response(\n",
    "        model_name=\"gpt-4o\",\n",
    "        user_message=get_user_prompt_paper_qna(paper, question),\n",
    "        system_message=system_prompt_paper_qna\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511c11e",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e65af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_paper_answer(url, question):\n",
    "    answer = paper_qna(url, question)\n",
    "    display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88856f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o\n",
      "With system prompt: You are a research assistant. Your job is to go th...\n",
      "With user prompt: You are looking at a paper titled Strategies for I...\n",
      "Using OpenAI with model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The paper \"Strategies for Improving the Resiliency of Distribution Networks in Electric Power Systems during Typhoon and Water-Logging Disasters\" employs several models to address the impact of extreme weather conditions on electric distribution networks and to propose methodologies for improving system resilience. The models used include:\n",
       "\n",
       "1. **Vulnerability Models**: \n",
       "   - **Distribution Network Towers and Lines Vulnerability Model**: These models use vulnerability curves to predict the failure probabilities of towers and lines based on wind speed. The probability is calculated using event probability models and fragility curves representing the likelihood of failure depending on the wind speed.\n",
       "   - **Substation and Buried Cable Vulnerability Model**: This model calculates the failure probabilities of substations and buried cables in response to water depth from flooding. It utilizes damage curves and vulnerability functions to determine the likelihood of substation failure due to flooding.\n",
       "\n",
       "2. **Dynamic Microgrid Reconstruction Mathematical Model**:\n",
       "   - This multi-objective optimization model is designed for reconstructing distribution networks dynamically in response to evolving fault scenarios during typhoon and water-logging disasters. It aims to maximize load supply and minimize switching operations by dynamically adjusting network topology, distributed generation dispatch, and operational strategies.\n",
       "   - The reconstruction is modeled as a second-order cone programming (SOCP) problem, involving constraints such as power flow balance, generator operation, and maintaining radial topology.\n",
       "\n",
       "These models collectively address the stochastic nature of disasters and propose strategies for real-time adaptability and resilience enhancement in power distribution networks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_paper_answer(\"d:/Projects/sandbox/data/energies.pdf\", \"What are the models used in this paper?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f89e38",
   "metadata": {},
   "source": [
    "# Presentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a074cbc",
   "metadata": {},
   "source": [
    "## PPT Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a571854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerPoint:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.slides = []\n",
    "        self.text = \"\"\n",
    "        self.title = \"No title found\"\n",
    "\n",
    "        if os.path.isfile(path):\n",
    "            try:\n",
    "                presentation = Presentation(path)\n",
    "                self._extract(presentation)\n",
    "                self.title = presentation.core_properties.title or self.slides[0] if self.slides else \"No title found\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading presentation: {e}\")\n",
    "        else:\n",
    "            print(f\"Invalid file path: {path}\")\n",
    "\n",
    "    def _extract(self, presentation):\n",
    "        all_text = []\n",
    "        for slide in presentation.slides:\n",
    "            slide_text = []\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                    slide_text.append(shape.text.strip())\n",
    "            combined_slide = \"\\n\".join(slide_text)\n",
    "            self.slides.append(combined_slide)\n",
    "            all_text.append(combined_slide)\n",
    "        self.text = \"\\n\\n\".join(all_text)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"PresentationFile(title='{self.title[:100]}...', slides={len(self.slides)}, text='{self.text[:1000]}...')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "95be6a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PresentationFile(title='PowerPoint Presentation...', slides=10, text='Wildfire Prediction\n",
      "Proposal\n",
      "\n",
      "Use cases\n",
      "Fire occurrence prediction\n",
      "Area burned and damage prediction\n",
      "Effect of weather\n",
      "Severe weather - Lightning\n",
      "Temperature rise\n",
      "Effect of human proceses\n",
      "\n",
      "Market\n",
      "**To add spending and loss in and due to wildfires in Canada, US and in general\n",
      "**Existing solutions and limitations\n",
      "\n",
      "Data\n",
      "Climate data \n",
      "Wildfire data\n",
      "**Vegetation Data\n",
      "**Human activity\n",
      "\n",
      "Model\n",
      "Proposed - ANN (1)\n",
      "\n",
      "Model II\n",
      "Comparison of models for australia - ann still the better choice because of short term memory (5)\n",
      "\n",
      "Impact\n",
      "Weather Network - goes with the brand image\n",
      "Trust - national provider \n",
      "Disaster management and urban and commercial planning\n",
      "Revenue streams\n",
      "Government - wildfire / Forest department\n",
      "International UN disaster management\n",
      "Tracking of carbon footprint etc. for environmental bodies like Environment Canada, UNEP\n",
      "Private settlements\n",
      "Wood/paper industries or suppliers\n",
      "Visibility and smoke level predictions for cities, air traffic, hospitals\n",
      "\n",
      "Cost\n",
      "** Cost of POC\n",
      "** Cost of data -...')\n"
     ]
    }
   ],
   "source": [
    "test_presentation_path = \"d:/Projects/sandbox/data/WildfirePrediction-Proposal-Draft.pptx\"\n",
    "presentation = PowerPoint(test_presentation_path)\n",
    "print(presentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee898425",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "987e069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_presentation_summary = \"You are an assistant that analyzes the contents of a presentation \\\n",
    "and provides a short summary in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8de1c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_presentation_summary(presentation):\n",
    "    user_prompt = f\"You are looking at a presentation titled {presentation.title}\"\n",
    "    user_prompt += \"\\nThe contents of this presentation is as follows; \\\n",
    "please provide a short summary of this presentation in markdown.\\n\\n\"\n",
    "    user_prompt += presentation.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a2d1a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_presentation(url):\n",
    "    presentation = PowerPoint(url)\n",
    "    response = get_model_response(\n",
    "        model_name=\"gpt-4o\",\n",
    "        user_message=get_user_prompt_presentation_summary(presentation),\n",
    "        system_message=system_prompt_presentation_summary\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307249b",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bc04dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_presentation_summary(url):\n",
    "    summary = summarize_presentation(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f457635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o\n",
      "With system prompt: You are an assistant that analyzes the contents of...\n",
      "With user prompt: You are looking at a presentation titled PowerPoin...\n",
      "Using OpenAI with model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Wildfire Prediction Proposal\n",
       "\n",
       "### Overview\n",
       "This presentation outlines a proposal for predicting wildfires, focusing on models that predict fire occurrence, the area burned, and the effects of weather and human processes. The proposal highlights advancements in the use of Artificial Neural Networks (ANNs) for accurate predictions and explores their potential impact on disaster management.\n",
       "\n",
       "### Use Cases\n",
       "- **Fire Occurrence Prediction:** Forecasting the likelihood of wildfire occurrences.\n",
       "- **Damage Prediction:** Estimating the potential area that could be burned.\n",
       "- **Weather Impact:** Understanding the role of severe weather, such as lightning and temperature rise.\n",
       "- **Human Processes:** Analyzing human activities that influence wildfires.\n",
       "\n",
       "### Market\n",
       "- **Financial Impact:** Pending data on wildfire-related spending and losses in Canada and the US.\n",
       "- **Existing Solutions:** Discussion on current solutions and their limitations.\n",
       "\n",
       "### Data Sources\n",
       "- Climate data\n",
       "- Wildfire data\n",
       "- Proposed inclusion of vegetation data and human activity data.\n",
       "\n",
       "### Model Proposal\n",
       "- **ANN Model I:** Proposed model leveraging ANNs.\n",
       "- **Model Comparison:** Comparison with models used in Australia showing the advantages of ANNs due to their effective short-term memory capabilities.\n",
       "\n",
       "### Impact & Benefits\n",
       "- Boosts brand image for weather networks.\n",
       "- Enhances trust as a national provider in disaster management.\n",
       "- Influences urban and commercial planning, benefiting government agencies, international bodies, and industries.\n",
       "- Potential revenue streams include government departments, international disaster management organizations, and private sectors such as wood and paper industries.\n",
       "- Improves visibility and smoke level predictions for public safety and industry operations.\n",
       "\n",
       "### Costs\n",
       "- Estimated cost for proof of concept (POC).\n",
       "- Data acquisition and storage expenses.\n",
       "- Training costs associated with model development.\n",
       "\n",
       "### Implementation\n",
       "Outlined steps for taking the proposed model from concept to application.\n",
       "\n",
       "### References / Resources\n",
       "- Review of ML applications in wildfire sciences - NRC (2020) [Read more](https://cdnsciencepub.com/doi/pdf/10.1139/er-2020-0019#refg23)\n",
       "- Wildland Fire Suppression and Partnerships by the DOI [Learn more](https://www.doi.gov/wildlandfire/suppression)\n",
       "- Forest fire risk prediction system, DOI: 10.1016/S0957-4174(03)00095-2\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_presentation_summary(\"d:/Projects/sandbox/data/WildfirePrediction-Proposal-Draft.pptx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebb902",
   "metadata": {},
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8bdc3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_presentation_qna = \"You are an assistant that analyzes the contents of a presentation \\\n",
    "and answers questions related to the content of the presentation, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "88769e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_presentation_qna(presentation, question):\n",
    "    user_prompt = f\"You are looking at a presentation titled {presentation.title}\"\n",
    "    user_prompt += \"\\nThe contents of this presentation is as follows \\n\\n\"\n",
    "    user_prompt += presentation.text\n",
    "    user_prompt += f\"\\n\\nPlease answer the following question related to this presentation: {question}\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b20e6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def presentation_qna(url, question):\n",
    "    presentation = PowerPoint(url)\n",
    "    response = get_model_response(\n",
    "        model_name=\"gpt-4o\",\n",
    "        user_message=get_user_prompt_website_qna(presentation, question),\n",
    "        system_message=system_prompt_website_qna\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1ffc7",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5c0bd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_presentation_answer(url, question):\n",
    "    answer = presentation_qna(url, question)\n",
    "    display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "53cd360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o\n",
      "With system prompt: You are an assistant that analyzes the contents of...\n",
      "With user prompt: You are looking at a website titled PowerPoint Pre...\n",
      "Using OpenAI with model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The proposed model for wildfire prediction on the website is an Artificial Neural Network (ANN). The use cases outlined include:\n",
       "\n",
       "- Fire occurrence prediction\n",
       "- Area burned and damage prediction\n",
       "- Effect of weather, specifically severe weather like lightning and temperature rise\n",
       "- Impact of human processes on wildfire occurrence and behavior"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_presentation_answer(\"d:/Projects/sandbox/data/WildfirePrediction-Proposal-Draft.pptx\", \"What is the model and use case proposed?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95c4cc",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e25a6",
   "metadata": {},
   "source": [
    "## Youtube Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5b6afd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoutubeVideo:\n",
    "    def __init__(self, url, language='en'):\n",
    "        \"\"\"\n",
    "        Initialize the YoutubeVideo object with the video URL and fetch its transcript.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.video_id = self._extract_video_id(url)\n",
    "        self.language = language\n",
    "        self.text = self._get_transcript()\n",
    "        self.title = f\"Video with ID {self.video_id}\"  \n",
    "\n",
    "    def _extract_video_id(self, url):\n",
    "        \"\"\"\n",
    "        Extract the video ID from the given YouTube URL.\n",
    "        \"\"\"\n",
    "        regex = r\"(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|\\S*\\?v=)|(?:youtu\\.be\\/))([a-zA-Z0-9_-]{11})\"\n",
    "        match = re.match(regex, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid YouTube URL\")\n",
    "\n",
    "    def _get_transcript(self):\n",
    "        \"\"\"\n",
    "        Fetch the transcript of the video using the YouTubeTranscriptApi.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            text = YouTubeTranscriptApi.get_transcript(self.video_id, languages=[self.language])\n",
    "            return \" \".join([item['text'] for item in text])\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        String representation of the YoutubeVideo object.\n",
    "        \"\"\"\n",
    "        return f\"YoutubeVideo(title='{self.title}', video_id='{self.video_id}', transcript='{self.text[:100]}...')\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88559f53",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7ff6c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_video_summary = \"You are an assistant that analyzes the contents of a video \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8b888929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_video_summary(video):\n",
    "    user_prompt = f\"You are looking at a video titled {video.title}\"\n",
    "    user_prompt += \"\\nThe contents of this video are transcribed as follows; \\\n",
    "please provide a short summary of this video in markdown. \\n\\n\"\n",
    "    user_prompt += video.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a22e907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_video(url):\n",
    "    video = YoutubeVideo(url)\n",
    "    response = get_model_response(\n",
    "        model_name=\"gpt-4o\",\n",
    "        user_message=get_user_prompt_video_summary(video),\n",
    "        system_message=system_prompt_video_summary\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f3425",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a92891d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_video_summary(url):\n",
    "    summary = summarize_video(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f4c8e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o\n",
      "With system prompt: You are an assistant that analyzes the contents of...\n",
      "With user prompt: You are looking at a video titled Video with ID 8H...\n",
      "Using OpenAI with model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This video explores homeopathy, a widely debated alternative medicine. It explains key principles, such as \"like cures like,\" where substances causing symptoms are used to treat them, and \"potentization,\" involving extreme dilution to enhance effectiveness. Criticisms arise due to the lack of scientific evidence supporting homeopathy's efficacy beyond placebo effects. Despite this, homeopathy remains popular, partly due to its personalized care and emphasis on empathy—an area modern medicine could potentially learn from. The video also discusses the financial scale of the homeopathy industry and its impact on public health. The video is produced by Kurzgesagt, announcing their relaunch of a German channel with new content."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_video_summary(\"https://www.youtube.com/watch?v=8HslUzw35mc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df54c1",
   "metadata": {},
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6c7c7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_video_qna = \"You are an assistant that analyzes the contents of a video \\\n",
    "and answers questions related to the content of the video transcription \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d8bbe748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_video_qna(video, question):\n",
    "    user_prompt = f\"You are looking at a video titled {video.title}\"\n",
    "    user_prompt += \"\\nThe contents of this video is as follows \\n\\n\"\n",
    "    user_prompt += video.text\n",
    "    user_prompt += f\"\\n\\nPlease answer the following question related to this video: {question}\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "75a89412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_qna(url, question):\n",
    "    video = YoutubeVideo(url)\n",
    "    response = get_model_response(\n",
    "        model_name=\"gpt-4o\",\n",
    "        user_message=get_user_prompt_video_qna(video, question),\n",
    "        system_message=system_prompt_video_qna\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae8ed29",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "feb30545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_video_answer(url, question):\n",
    "    answer = video_qna(url, question)\n",
    "    display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o\n",
      "With system prompt: You are an assistant that analyzes the contents of...\n",
      "With user prompt: You are looking at a video titled Video with ID 8H...\n",
      "Using OpenAI with model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The video mentions that the global market for homeopathy is expected to reach over $17 billion by 2024. This suggests that homeopathy is a significant industry with substantial financial influence, comparable to other sectors within the pharmaceutical landscape."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_video_answer(\"https://www.youtube.com/watch?v=8HslUzw35mc\", \"What is the financial share of homeopathy?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
